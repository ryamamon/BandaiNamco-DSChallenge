{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノイズ付加関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(raw):\n",
    "    noise = np.array([(-2*v)*np.random.rand()+v for v in raw.flatten()]).reshape(raw.shape[0],raw.shape[1])\n",
    "    noised_raw = noise + raw\n",
    "    return noised_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 80\n",
    "def load_batch(n_batches=1,is_testing=False):\n",
    "\n",
    "    base_path = '../input/raw/'\n",
    "    \n",
    "    if not is_testing:\n",
    "        path = sorted(os.listdir(base_path))[:val]\n",
    "    else:\n",
    "        path = sorted(os.listdir(base_path))[val:]\n",
    "    \n",
    "    # x_data:ノイズありmel, y_data:ノイズなしmel\n",
    "    x_data, y_data = [], []\n",
    "    for _ in range(n_batches):\n",
    "        for mel_path in path:\n",
    "            raw = np.load(base_path + mel_path)\n",
    "            \n",
    "            for i in range(0,raw.shape[0]-mel_shape[0],3):\n",
    "                for j in range(0,raw.shape[1]-mel_shape[1],3):\n",
    "                    y = raw[i:i+mel_shape[0],j:j+mel_shape[1]]\n",
    "                    x = add_noise(y)\n",
    "                    \n",
    "                    x = x.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    y = y.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    \n",
    "                    x_data.append(x)\n",
    "                    y_data.append(y)\n",
    "\n",
    "    return  np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract\n",
    "\n",
    "def create_dncnn():\n",
    "    inpt = Input(shape=(mel_shape[0],mel_shape[1],1))\n",
    "    # 1st layer, Conv+relu\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n",
    "    x = Activation('relu')(x)\n",
    "    # 15 layers, Conv+BN+relu\n",
    "    for i in range(15):\n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)\n",
    "        x = Activation('relu')(x)   \n",
    "    # last layer, Conv\n",
    "    x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "    x = Subtract()([inpt, x])   # input - noise\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_shape = (32,32) # input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_batch(n_batches=1,is_testing=False)\n",
    "x_test, y_test = load_batch(n_batches=1,is_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_dncnn()\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 153472 samples, validate on 41184 samples\n",
      "Epoch 1/3\n",
      "153472/153472 [==============================] - 124s 809us/sample - loss: 0.9236 - val_loss: 0.8657\n",
      "Epoch 2/3\n",
      "153472/153472 [==============================] - 119s 778us/sample - loss: 0.6407 - val_loss: 0.6177\n",
      "Epoch 3/3\n",
      "153472/153472 [==============================] - 119s 777us/sample - loss: 0.5639 - val_loss: 0.6149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdb9e0aa0b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noisedデータにモデルを適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(noised_tgt):\n",
    "    vector_dict = {}\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            vector_dict[(i,j)] = []\n",
    "\n",
    "    x_test = []\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            v = noised_tgt[i:i+mel_shape[0],j:j+mel_shape[1]].reshape(mel_shape[0],mel_shape[1],1)\n",
    "            x_test.append(v)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    v_noise = model.predict(x_test).reshape(-1,mel_shape[0],mel_shape[1])\n",
    "    c = 0\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            for i2 in range(v_noise[0].shape[0]):\n",
    "                for j2 in range(v_noise[0].shape[1]):\n",
    "                    vector_dict[(i+i2,j+j2)].append(v_noise[c][i2][j2])\n",
    "            c += 1\n",
    "            \n",
    "    pred = np.copy(noised_tgt)\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            if len(vector_dict[(i,j)]) > 0:\n",
    "                value = np.mean(vector_dict[(i,j)])\n",
    "                if value > 0:\n",
    "                    pred[i][j] = value\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- val_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 4.316797298967814\n",
      "after : 0.7051285473010405\n"
     ]
    }
   ],
   "source": [
    "base_path = '../input/raw/'\n",
    "path = sorted(os.listdir(base_path))[val:]\n",
    "\n",
    "targets = []\n",
    "noises = []\n",
    "preds = []\n",
    "\n",
    "for mel_path in path:\n",
    "    raw = np.load(base_path + mel_path)\n",
    "    noised_raw = add_noise(raw)\n",
    "    pred = fitting(noised_raw)\n",
    "    \n",
    "    targets.append(raw)\n",
    "    noises.append(noised_raw)\n",
    "    preds.append(pred)\n",
    "    \n",
    "    \n",
    "print('before:',np.mean([mse(targets[i].flatten(),noises[i].flatten()) for i in range(len(targets))]))\n",
    "print('after :',np.mean([mse(targets[i].flatten(),preds[i].flatten()) for i in range(len(targets))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- submit_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '002_dncnn'\n",
    "path = '../output/unzip_data/%s/' % (name)\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "noised_path = '../input/noised_tgt/'\n",
    "\n",
    "for p in sorted(os.listdir(noised_path)):\n",
    "    noised_tgt = np.load(noised_path+p)\n",
    "    clean_tgt = fitting(noised_tgt)\n",
    "                    \n",
    "    np.save(path+p[7:],clean_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataをzip化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/share/BandaiNamco-DSChallenge/output/zip_data/002_dncnn.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "base = '../output/'\n",
    "unzip_path = base+'unzip_data/'+name\n",
    "zip_path = base+'zip_data/'+name\n",
    "shutil.make_archive(zip_path,\"zip\",root_dir = unzip_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
