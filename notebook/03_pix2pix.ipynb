{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pix2pixを用いた手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノイズ付加関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(raw):\n",
    "    noise = np.array([(-2*v)*np.random.rand()+v for v in raw.flatten()]).reshape(raw.shape[0],raw.shape[1])\n",
    "    noised_raw = noise + raw\n",
    "    return noised_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 80\n",
    "def load_batch(n_batches=1,is_testing=False):\n",
    "\n",
    "    base_path = '../input/raw/'\n",
    "    \n",
    "    if not is_testing:\n",
    "        path = sorted(os.listdir(base_path))[:val]\n",
    "    else:\n",
    "        path = sorted(os.listdir(base_path))[val:]\n",
    "    \n",
    "    # x_data:ノイズありmel, y_data:ノイズなしmel\n",
    "    x_data, y_data = [], []\n",
    "    for _ in range(n_batches):\n",
    "        for mel_path in path:\n",
    "            raw = np.load(base_path + mel_path)\n",
    "            \n",
    "            for i in range(0,raw.shape[0]-mel_shape[0],3):\n",
    "                for j in range(0,raw.shape[1]-mel_shape[1],3):\n",
    "                    y = raw[i:i+mel_shape[0],j:j+mel_shape[1]]\n",
    "                    x = add_noise(y)\n",
    "                    \n",
    "                    x = x.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    y = y.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    \n",
    "                    x_data.append(x)\n",
    "                    y_data.append(y)\n",
    "\n",
    "    return  np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract\n",
    "\n",
    "def create_dncnn():\n",
    "    inpt = Input(shape=(mel_shape[0],mel_shape[1],1))\n",
    "    # 1st layer, Conv+relu\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n",
    "    x = Activation('relu')(x)\n",
    "    # 15 layers, Conv+BN+relu\n",
    "    for i in range(15):\n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)\n",
    "        x = Activation('relu')(x)   \n",
    "    # last layer, Conv\n",
    "    x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "    x = Subtract()([inpt, x])   # input - noise\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_shape = (32,32) # input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_batch(n_batches=1,is_testing=False)\n",
    "x_test, y_test = load_batch(n_batches=1,is_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = create_dncnn()\n",
    "generator.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 153472 samples, validate on 41184 samples\n",
      "Epoch 1/3\n",
      "153472/153472 [==============================] - 123s 803us/sample - loss: 0.9368 - val_loss: 0.7797\n",
      "Epoch 2/3\n",
      "153472/153472 [==============================] - 119s 777us/sample - loss: 0.6339 - val_loss: 0.6601\n",
      "Epoch 3/3\n",
      "153472/153472 [==============================] - 119s 776us/sample - loss: 0.5540 - val_loss: 0.5893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f32351d6f28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generatorは事前学習させる\n",
    "generator.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def create_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=((mel_shape[0],mel_shape[1],1)), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    img = Input(shape=(mel_shape[0],mel_shape[1],1))\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_noise = Input(shape=(mel_shape[0],mel_shape[1],1))\n",
    "\n",
    "mel_fake = generator(mel_noise)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "valid = discriminator(mel_fake)\n",
    "\n",
    "combined = Model(inputs=mel_noise, outputs=[valid,mel_fake])\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "combined.compile(loss=['mse','mse'],\n",
    "                 loss_weights=[1, 100],\n",
    "                 optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    base_path = '../input/raw/'\n",
    "    path = os.listdir(base_path)[:val]\n",
    "\n",
    "    for n in range(len(path)):\n",
    "        batch = path[n*len(path):(n+1)*len(path)]\n",
    "        for mel_path in batch:\n",
    "            \n",
    "            x_data, y_data = [], []\n",
    "            mel = np.load(base_path + mel_path)\n",
    "\n",
    "            for i in range(0,mel.shape[0]-mel_shape[0],5):\n",
    "                for j in range(0,mel.shape[1]-mel_shape[1],5):\n",
    "                    y = mel[i:i+mel_shape[0],j:j+mel_shape[1]]\n",
    "                    x = add_noise(y)\n",
    "                    \n",
    "                    x = x.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    y = y.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    \n",
    "                    x_data.append(x)\n",
    "                    y_data.append(y)\n",
    "                \n",
    "            yield np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    d_lo = []\n",
    "    d_ac = []\n",
    "    g_lo = []\n",
    "    for batch_i, (x_train, y_train) in enumerate(load_data()):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Condition on B and generate a translated version\n",
    "        mels_fake = generator.predict(x_train)\n",
    "        \n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((len(x_train), 1))\n",
    "        fake = np.zeros((len(x_train), 1))\n",
    "\n",
    "        # Train the discriminators (original images = real / generated = Fake)\n",
    "        d_loss_real = discriminator.train_on_batch(y_train, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(mels_fake, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        # Train the generators\n",
    "        g_loss = combined.train_on_batch(x_train, [valid,y_train])\n",
    "        \n",
    "        d_lo.append(d_loss[0])\n",
    "        d_ac.append(d_loss[1])\n",
    "        g_lo.append(g_loss)\n",
    "        \n",
    "\n",
    "    # Plot the progress\n",
    "    if epoch % 5 == 0:\n",
    "        print (\"epoch:%d [D loss: %f, acc: %f] [G loss: %f]\" % \n",
    "               (epoch,  np.mean(d_lo),100*np.mean(d_ac),np.mean(g_lo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noisedデータにモデルを適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(noised_tgt):\n",
    "    vector_dict = {}\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            vector_dict[(i,j)] = []\n",
    "\n",
    "    x_test = []\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            v = noised_tgt[i:i+mel_shape[0],j:j+mel_shape[1]].reshape(mel_shape[0],mel_shape[1],1)\n",
    "            x_test.append(v)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    v_noise = generator.predict(x_test).reshape(-1,mel_shape[0],mel_shape[1])\n",
    "    c = 0\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            for i2 in range(v_noise[0].shape[0]):\n",
    "                for j2 in range(v_noise[0].shape[1]):\n",
    "                    vector_dict[(i+i2,j+j2)].append(v_noise[c][i2][j2])\n",
    "            c += 1\n",
    "            \n",
    "    pred = np.copy(noised_tgt)\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            if len(vector_dict[(i,j)]) > 0:\n",
    "                value = np.mean(vector_dict[(i,j)])\n",
    "                pred[i][j] = value\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- val_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 4.279852637887082\n",
      "after : 0.5917038743068908\n"
     ]
    }
   ],
   "source": [
    "base_path = '../input/raw/'\n",
    "path = sorted(os.listdir(base_path))[val:]\n",
    "\n",
    "targets = []\n",
    "noises = []\n",
    "preds = []\n",
    "\n",
    "for mel_path in path:\n",
    "    raw = np.load(base_path + mel_path)\n",
    "    noised_raw = add_noise(raw)\n",
    "    pred = fitting(noised_raw)\n",
    "    \n",
    "    targets.append(raw)\n",
    "    noises.append(noised_raw)\n",
    "    preds.append(pred)\n",
    "    \n",
    "    \n",
    "print('before:',np.mean([mse(targets[i].flatten(),noises[i].flatten()) for i in range(len(targets))]))\n",
    "print('after :',np.mean([mse(targets[i].flatten(),preds[i].flatten()) for i in range(len(targets))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- submit_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '003_pix2pix'\n",
    "path = '../output/unzip_data/%s/' % (name)\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "noised_path = '../input/noised_tgt/'\n",
    "\n",
    "for p in sorted(os.listdir(noised_path)):\n",
    "    noised_tgt = np.load(noised_path+p)\n",
    "    clean_tgt = fitting(noised_tgt)\n",
    "                    \n",
    "    np.save(path+p[7:],clean_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataをzip化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/share/BandaiNamco-DSChallenge/output/zip_data/003_pix2pix.zip'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "base = '../output/'\n",
    "unzip_path = base+'unzip_data/'+name\n",
    "zip_path = base+'zip_data/'+name\n",
    "shutil.make_archive(zip_path,\"zip\",root_dir = unzip_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
