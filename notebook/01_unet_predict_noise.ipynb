{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノイズ付加関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(raw):\n",
    "    noise = np.array([(-2*v)*np.random.rand()+v for v in raw.flatten()]).reshape(raw.shape[0],raw.shape[1])\n",
    "    noised_raw = noise + raw\n",
    "    return noised_raw, noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 80\n",
    "def load_batch(n_batches=1,is_testing=False):\n",
    "\n",
    "    base_path = '../input/raw/'\n",
    "    \n",
    "    if not is_testing:\n",
    "        path = sorted(os.listdir(base_path))[:val]\n",
    "    else:\n",
    "        path = sorted(os.listdir(base_path))[val:]\n",
    "    \n",
    "    # x_data:ノイズありmel, y_data:ノイズ\n",
    "    x_data, y_data = [], []\n",
    "    for _ in range(n_batches):\n",
    "        for mel_path in path:\n",
    "            raw = np.load(base_path + mel_path)\n",
    "            \n",
    "            for i in range(0,raw.shape[0]-mel_shape[0],3):\n",
    "                for j in range(0,raw.shape[1]-mel_shape[1],3):\n",
    "                    tgt = raw[i:i+mel_shape[0],j:j+mel_shape[1]]\n",
    "                    x,y = add_noise(tgt)\n",
    "                    \n",
    "                    x = x.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    y = y.reshape(mel_shape[0],mel_shape[1],1)\n",
    "                    \n",
    "                    x_data.append(x)\n",
    "                    y_data.append(y)\n",
    "\n",
    "    return  np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,UpSampling2D, BatchNormalization, Activation, Input, Concatenate, MaxPool2D, Conv2DTranspose, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "def create_block(input, chs):\n",
    "    x = input\n",
    "    for i in range(2):\n",
    "        x = Conv2D(chs, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def create_unet(use_skip_connections=True, grayscale_inputs=True):\n",
    "    if grayscale_inputs:\n",
    "        input = Input((mel_shape[0],mel_shape[1],1))\n",
    "    else:\n",
    "        input = Input((mel_shape[0],mel_shape[1],3))\n",
    "        \n",
    "    # Encoder\n",
    "    block1 = create_block(input, 64)\n",
    "    x = MaxPool2D(2)(block1)\n",
    "    block2 = create_block(x, 128)\n",
    "    x = MaxPool2D(2)(block2)\n",
    "    block3 = create_block(x, 256)\n",
    "    x = MaxPool2D(2)(block3)\n",
    "    block4 = create_block(x, 512)\n",
    "    # Middle\n",
    "    x = MaxPool2D(2)(block4)\n",
    "    x = create_block(x, 1024)\n",
    "    # Decoder\n",
    "    x = Conv2DTranspose(512, kernel_size=2, strides=2)(x) # TPUだとUpsamplingやK.resize_imageが使えない\n",
    "    if use_skip_connections: x = Concatenate()([block4, x])\n",
    "    x = create_block(x, 512)\n",
    "    x = Conv2DTranspose(256, kernel_size=2, strides=2)(x)\n",
    "    if use_skip_connections: x = Concatenate()([block3, x])\n",
    "    x = create_block(x, 256)\n",
    "    x = Conv2DTranspose(128, kernel_size=2, strides=2)(x)\n",
    "    if use_skip_connections: x = Concatenate()([block2, x])\n",
    "    x = create_block(x, 128)\n",
    "    x = Conv2DTranspose(64, kernel_size=2, strides=2)(x)\n",
    "    if use_skip_connections: x = Concatenate()([block1, x])\n",
    "    x = create_block(x, 64)\n",
    "    # output\n",
    "    x = Conv2D(3, 1)(x)\n",
    "    x = Conv2D(1, 1)(x)\n",
    "\n",
    "    return Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_shape = (32,32) # input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_batch(n_batches=1,is_testing=False)\n",
    "x_test, y_test = load_batch(n_batches=1,is_testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_unet()\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 153472 samples, validate on 41184 samples\n",
      "Epoch 1/3\n",
      "153472/153472 [==============================] - 248s 2ms/sample - loss: 0.9054 - val_loss: 0.6645\n",
      "Epoch 2/3\n",
      "153472/153472 [==============================] - 243s 2ms/sample - loss: 0.7091 - val_loss: 0.6509\n",
      "Epoch 3/3\n",
      "153472/153472 [==============================] - 242s 2ms/sample - loss: 0.6064 - val_loss: 0.6724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd67c6400b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=3,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noisedデータにモデルを適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(noised_tgt):\n",
    "    vector_dict = {}\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            vector_dict[(i,j)] = []\n",
    "\n",
    "    x_test = []\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            v = noised_tgt[i:i+mel_shape[0],j:j+mel_shape[1]].reshape(mel_shape[0],mel_shape[1],1)\n",
    "            x_test.append(v)\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    v_noise = model.predict(x_test).reshape(-1,mel_shape[0],mel_shape[1])\n",
    "    c = 0\n",
    "    for i in range(0,noised_tgt.shape[0]-mel_shape[0],5):\n",
    "        for j in range(0,noised_tgt.shape[1]-mel_shape[1],5):\n",
    "            for i2 in range(v_noise[0].shape[0]):\n",
    "                for j2 in range(v_noise[0].shape[1]):\n",
    "                    vector_dict[(i+i2,j+j2)].append(v_noise[c][i2][j2])\n",
    "            c += 1\n",
    "            \n",
    "    pred = np.copy(noised_tgt)\n",
    "    for i in range(noised_tgt.shape[0]):\n",
    "        for j in range(noised_tgt.shape[1]):\n",
    "            if len(vector_dict[(i,j)]) > 0:\n",
    "                value = np.mean(vector_dict[(i,j)])\n",
    "                pred[i][j] = pred[i][j] - value\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- val_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: 4.491250343960011\n",
      "after : 0.8852461199002402\n"
     ]
    }
   ],
   "source": [
    "base_path = '../input/raw/'\n",
    "path = sorted(os.listdir(base_path))[val:]\n",
    "\n",
    "targets = []\n",
    "noises = []\n",
    "preds = []\n",
    "\n",
    "for mel_path in path:\n",
    "    raw = np.load(base_path + mel_path)\n",
    "    noised_raw, _ = add_noise(raw)\n",
    "    pred = fitting(noised_raw)\n",
    "    \n",
    "    targets.append(raw)\n",
    "    noises.append(noised_raw)\n",
    "    preds.append(pred)\n",
    "    \n",
    "    \n",
    "print('before:',np.mean([mse(targets[i].flatten(),noises[i].flatten()) for i in range(len(targets))]))\n",
    "print('after :',np.mean([mse(targets[i].flatten(),preds[i].flatten()) for i in range(len(targets))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- submit_dataに対して実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '001_unet'\n",
    "path = '../output/unzip_data/%s/' % (name)\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "noised_path = '../input/noised_tgt/'\n",
    "\n",
    "for p in sorted(os.listdir(noised_path)):\n",
    "    noised_tgt = np.load(noised_path+p)\n",
    "    clean_tgt = fitting(noised_tgt)\n",
    "                    \n",
    "    np.save(path+p[7:],clean_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataをzip化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/share/BandaiNamco-DSChallenge/output/zip_data/001_unet.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "base = '../output/'\n",
    "unzip_path = base+'unzip_data/'+name\n",
    "zip_path = base+'zip_data/'+name\n",
    "shutil.make_archive(zip_path,\"zip\",root_dir = unzip_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
